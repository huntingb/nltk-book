{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"colorless\"\n",
    "s = s[:4] + \"u\" + s[4:]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-aaron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish\n",
      "run\n",
      "nation\n",
      "do\n",
      "heat\n"
     ]
    }
   ],
   "source": [
    "print(\"dishes\"[:-2])\n",
    "print(\"running\"[:-4])\n",
    "print(\"nationality\"[:-5])\n",
    "print(\"undo\"[2:])\n",
    "print(\"preheat\"[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "choice-clinic",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3c716c0a9441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "\"cat\"[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "correct-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnyPto\n",
      "nhy to\n"
     ]
    }
   ],
   "source": [
    "monty = \"Monty Python\"\n",
    "print(monty[::2])\n",
    "print(monty[::-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerous-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nohtyP ytnoM'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corrected-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Alphas}98323\n",
      "None\n",
      "{A} few words {To} {Demonstrate}\n",
      "None\n",
      "{pt} {pot} {paat} peeet\n",
      "None\n",
      "{1} {120} {120.345} {127.0}...\n",
      "None\n",
      "{cat} {bat} pt {AeA} woot\n",
      "None\n",
      "{This} {1234} {is} {456} {a} {test} {678} {sentence}{.}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# a. One or more of any sequence of alphabetical chars, upper or lowercase\n",
    "print(nltk.re_show(r\"[a-zA-Z]+\", \"Alphas98323\"))\n",
    "# b. One uppercase letter followed by zero or more lowercase letters\n",
    "print(nltk.re_show(r\"[A-Z][a-z]*\", \"A few words To Demonstrate\"))\n",
    "# c. \"p\" followed by up to 2 vowels, followed by \"t\"\n",
    "print(nltk.re_show(r\"p[aeiou]{,2}t\", \"pt pot paat peeet\"))\n",
    "# d. Number with an optional decimal value\n",
    "print(nltk.re_show(r\"\\d+(\\.\\d+)?\", \"1 120 120.345 127.0...\"))\n",
    "# e. Zero or more CVC sequences (capital vowel allowed at word boundaries)\n",
    "print(nltk.re_show(r\"[^aeiou][aeiou][^aeiou]\", \"cat bat pt AeA woot\"))\n",
    "# f. One or more word characters or one or more chars that are not word or whitespace i.e. digits\n",
    "print(nltk.re_show(r\"\\w+|[^\\w\\s]+\", \"This 1234 is 456 a test 678 sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-outline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{The} quick brown and red fox jumped over {a} lazy dog and {an} anthill\n"
     ]
    }
   ],
   "source": [
    "determiner = r\"\\b[Tt]he|[Aa]n?\\b\"\n",
    "nltk.re_show(determiner, \"The quick brown and red fox jumped over a lazy dog and an anthill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mexican-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2*5*10} = {1000 / 10}\n"
     ]
    }
   ],
   "source": [
    "expr = r\"(\\d+(\\.\\d+)?\\s?[+\\-*/]\\s?)+\\d+(\\.\\d+)?\"\n",
    "nltk.re_show(expr, \"2*5*10 = 1000 / 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpine-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Natural Language Toolkit — NLTK 3.5 documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NLTK 3.5 documentation\n",
      "\n",
      "next |\n",
      "          modules |\n",
      "          index\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Natural Language Toolkit¶\n",
      "NLTK is a leading platform for building Python programs to work with human language data.\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical\n",
      "resources such as WordNet,\n",
      "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\n",
      "wrappers for industrial-strength NLP libraries,\n",
      "and an active discussion forum.\n",
      "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\n",
      "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\n",
      "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
      "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\n",
      "and “an amazing library to play with natural language.”\n",
      "Natural Language Processing with Python provides a practical\n",
      "introduction to programming for language processing.\n",
      "Written by the creators of NLTK, it guides the reader through the fundamentals\n",
      "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\n",
      "and more.\n",
      "The online version of the book has been been updated for Python 3 and NLTK 3.\n",
      "(The original Python 2 version is still available at http://nltk.org/book_1ed.)\n",
      "\n",
      "Some simple things you can do with NLTK¶\n",
      "Tokenize and tag some text:\n",
      ">>> import nltk\n",
      ">>> sentence = \"\"\"At eight o'clock on Thursday morning\n",
      "... Arthur didn't feel very good.\"\"\"\n",
      ">>> tokens = nltk.word_tokenize(sentence)\n",
      ">>> tokens\n",
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning',\n",
      "'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
      ">>> tagged = nltk.pos_tag(tokens)\n",
      ">>> tagged[0:6]\n",
      "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'),\n",
      "('Thursday', 'NNP'), ('morning', 'NN')]\n",
      "\n",
      "\n",
      "Identify named entities:\n",
      ">>> entities = nltk.chunk.ne_chunk(tagged)\n",
      ">>> entities\n",
      "Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'),\n",
      "           ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'),\n",
      "       Tree('PERSON', [('Arthur', 'NNP')]),\n",
      "           ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'),\n",
      "           ('very', 'RB'), ('good', 'JJ'), ('.', '.')])\n",
      "\n",
      "\n",
      "Display a parse tree:\n",
      ">>> from nltk.corpus import treebank\n",
      ">>> t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
      ">>> t.draw()\n",
      "\n",
      "\n",
      "\n",
      "NB. If you publish work that uses NLTK, please cite the NLTK book as\n",
      "follows:\n",
      "\n",
      "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  O’Reilly Media Inc.\n",
      "\n",
      "\n",
      "\n",
      "Next Steps¶\n",
      "\n",
      "sign up for release announcements\n",
      "join in the discussion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents¶\n",
      "\n",
      "\n",
      "NLTK News\n",
      "Installing NLTK\n",
      "Installing NLTK Data\n",
      "Contribute to NLTK\n",
      "FAQ\n",
      "Wiki\n",
      "API\n",
      "HOWTO\n",
      "\n",
      "\n",
      "\n",
      "Index\n",
      "Module Index\n",
      "Search Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "NLTK News\n",
      "Installing NLTK\n",
      "Installing NLTK Data\n",
      "Contribute to NLTK\n",
      "FAQ\n",
      "Wiki\n",
      "API\n",
      "HOWTO\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "next |\n",
      "            modules |\n",
      "            index\n",
      "\n",
      "\n",
      "\n",
      "Show Source\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        © Copyright 2020, NLTK Project.\n",
      "      Last updated on Apr 13, 2020.\n",
      "      Created using Sphinx 2.4.4.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_markup(url):\n",
    "    html = request.urlopen(url).read().decode(\"utf8\")\n",
    "    raw = BeautifulSoup(html, \"html.parser\").get_text()\n",
    "    return raw\n",
    "\n",
    "print(remove_markup(\"http://nltk.org/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statutory-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is a file with example text.\\nI like pizza and apple pie.\\nIt cost $15.50. I work at the D.M.V.\\nI have a wrist-watch... It cost about $350.00\\nI bought it on 3/15/2019. \\nMy name is Bob.\\nAll my life, my name has been Bob (because my parents named me that. Thank you dad!). \\nMy Dad's name is William Chillingsworth. He admires John F. Kennedy. J.F.K. got shot on November 22, 1963, at 12:30 p.m.\\nDo you think I'm weird?\\nGlobe earth/helio-centric model seems suspicious. Probably N.A.S.A hoax!\\nI just found $100 on the ground. Neat!\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(f):\n",
    "    file = open(f)\n",
    "    s = file.read()\n",
    "    file.close()\n",
    "    return s\n",
    "\n",
    "load(\"corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "further-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'file',\n",
       " 'with',\n",
       " 'example',\n",
       " 'text',\n",
       " '.',\n",
       " 'I',\n",
       " 'like',\n",
       " 'pizza',\n",
       " 'and',\n",
       " 'apple',\n",
       " 'pie',\n",
       " '.',\n",
       " 'It',\n",
       " 'cost',\n",
       " '$15.50',\n",
       " '.',\n",
       " 'I',\n",
       " 'work',\n",
       " 'at',\n",
       " 'the',\n",
       " 'D.M.V.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'wrist',\n",
       " 'watch',\n",
       " '...',\n",
       " 'It',\n",
       " 'cost',\n",
       " 'about',\n",
       " '$350.00',\n",
       " 'I',\n",
       " 'bought',\n",
       " 'it',\n",
       " 'on',\n",
       " '3',\n",
       " '15',\n",
       " '2019',\n",
       " '.',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Bob',\n",
       " '.',\n",
       " 'All',\n",
       " 'my',\n",
       " 'life',\n",
       " ',',\n",
       " 'my',\n",
       " 'name',\n",
       " 'has',\n",
       " 'been',\n",
       " 'Bob',\n",
       " '(',\n",
       " 'because',\n",
       " 'my',\n",
       " 'parents',\n",
       " 'named',\n",
       " 'me',\n",
       " 'that',\n",
       " '.',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'dad',\n",
       " ')',\n",
       " '.',\n",
       " 'My',\n",
       " 'Dad',\n",
       " \"'\",\n",
       " 's',\n",
       " 'name',\n",
       " 'is',\n",
       " 'William',\n",
       " 'Chillingsworth',\n",
       " '.',\n",
       " 'He',\n",
       " 'admires',\n",
       " 'John',\n",
       " 'F.',\n",
       " 'Kennedy',\n",
       " '.',\n",
       " 'J.F.K.',\n",
       " 'got',\n",
       " 'shot',\n",
       " 'on',\n",
       " 'November',\n",
       " '22',\n",
       " ',',\n",
       " '1963',\n",
       " ',',\n",
       " 'at',\n",
       " '12',\n",
       " ':',\n",
       " '30',\n",
       " 'p',\n",
       " '.',\n",
       " 'm',\n",
       " '.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'weird',\n",
       " '?',\n",
       " 'Globe',\n",
       " 'earth',\n",
       " 'helio',\n",
       " 'centric',\n",
       " 'model',\n",
       " 'seems',\n",
       " 'suspicious',\n",
       " '.',\n",
       " 'Probably',\n",
       " 'N.A.S.',\n",
       " 'A',\n",
       " 'hoax',\n",
       " 'I',\n",
       " 'just',\n",
       " 'found',\n",
       " '$100',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " '.',\n",
       " 'Neat']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\"\"(?x)     # set flag to allow verbose regexps\n",
    "    (?:[A-Z]\\.)+       # abbreviations\n",
    "  | \\w+(?:-w\\+)*       # words with optional internal hyphens\n",
    "  | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages\n",
    "  | \\.\\.\\.             # ellipses\n",
    "  | [][.,;\"'?():-_`]   # punctuation tokens\n",
    "\"\"\"\n",
    "\n",
    "words = load(\"corpus.txt\")\n",
    "nltk.regexp_tokenize(words, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\"\"(?x)                                  # set verbose flag\n",
    "    \\$\\d+(\\.\\d{2})?                                # monetary amounts\n",
    "  | \\d{,2}/d{,2}/d\\{2,4}                           # dates\n",
    "  | [A-Z][a-z]+ \\d{,2}(st|nd|th)?, \\d{4}           # another format for dates, this one could be improved because it could match something like 'Zz 3nd 8907' but for the purposes of this exercise we will assume strings that conform to this pattern that are not dates are rare\n",
    "  | \\d{,2}:\\d{2}( a.m. | p.m.)?                    # times\n",
    "  | [A-Z][a-z]+ ([A-Z][a-z]+|[A-Z]\\.)? [A-Z][a-z]+ # full name with optional middle name or initial\n",
    "  | (?:[A-Z]\\.)+                                   # name of organization\n",
    "\"\"\"\n",
    "\n",
    "nltk.regexp_tokenize(words, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assumed-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3),\n",
       " ('dog', 3),\n",
       " ('gave', 4),\n",
       " ('John', 4),\n",
       " ('the', 3),\n",
       " ('newspaper', 9)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [\"The\", \"dog\", \"gave\", \"John\", \"the\", \"newspaper\"]\n",
    "result = [(word, len(word)) for word in sent]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "likely-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "q\n",
      "u\n",
      "i\n",
      "c\n",
      "k\n",
      " \n",
      "b\n",
      "r\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "x\n"
     ]
    }
   ],
   "source": [
    "s = \"The quick brown fox\"\n",
    "for i in s:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "labeled-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox\\tjumped\\tover\\tthe\\tlazy', 'dog']\n",
      "['The quick brown fox', 'jumped', 'over', 'the', 'lazy dog']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-21ce4acbdd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "s = \"The quick brown fox\\tjumped\\tover\\tthe\\tlazy dog\"\n",
    "print(s.split(\" \"))\n",
    "print(s.split(\"\\t\"))\n",
    "print(s.split(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sapphire-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[1, 4, 2, 3, 5]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# words.sort() sorts the list in place but sorted(words) returns a new list\n",
    "nums = [1, 4, 2, 3, 5]\n",
    "sorted_nums = sorted(nums)\n",
    "print(sorted_nums)\n",
    "print(nums)\n",
    "nums.sort()\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electronic-spine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333\n",
      "21\n",
      "21\n",
      "3333333\n"
     ]
    }
   ],
   "source": [
    "print(\"3\" * 7)\n",
    "print(3 * 7)\n",
    "print(int(\"3\") * 7)\n",
    "print(str(3) * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "anticipated-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prog import monty\n",
    "monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "variable-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prog\n",
    "prog.monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intermediate-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown Cthulhu jumped over the lazy centipede'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"The quick brown %6s jumped over the lazy %-6s\" % (\"Cthulhu\", \"centipede\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broken-international",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What',\n",
       " 'Wheel',\n",
       " 'When',\n",
       " 'Whenever',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'White',\n",
       " 'Whitelist',\n",
       " 'Whne',\n",
       " 'Whole',\n",
       " 'Why',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'whatsoever',\n",
       " 'wheel',\n",
       " 'wheeling',\n",
       " 'whell',\n",
       " 'when',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereas',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whilst',\n",
       " 'white',\n",
       " 'whitelist',\n",
       " 'whitelisting',\n",
       " 'whitespace',\n",
       " 'whith',\n",
       " 'whole',\n",
       " 'whose',\n",
       " 'why'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import webtext\n",
    "firefox = webtext.raw(\"firefox.txt\")\n",
    "pattern = r\"[Ww]h\\w+\"\n",
    "set(re.findall(pattern, firefox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "photographic-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fuzzy', '53'],\n",
       " ['wuzzy', '42'],\n",
       " ['was', '23'],\n",
       " ['a', '6'],\n",
       " ['bear', '65'],\n",
       " ['']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(\"frequencies.txt\").readlines()\n",
    "freqs = []\n",
    "for line in lines:\n",
    "    freqs.append(line.strip().split(\" \"))\n",
    "freqs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "selective-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From today's featured article\n",
      "\n",
      "\n",
      "Myuchelys purvisi  remains the senior synonym for the Manning River snapping turtle.\n",
      "\n",
      "The Wells and Wellington affair was a dispute involving the Australian Journal of Herpetology, a scientific journal on the study of amphibians and reptiles published beginning in 1981 by the Australian Herpetologists' League. Richard Wells, a student, served as the editor-in-chief of the peer-reviewed periodical, with an editorial board of three researchers. Wells stopped communi\n"
     ]
    }
   ],
   "source": [
    "wiki = remove_markup(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "start = wiki.index(\"From today's featured article\")\n",
    "print(wiki[start:start+500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "opening-arcade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles',\n",
       " 'arts',\n",
       " 'portals',\n",
       " 'purvisi',\n",
       " 'involving',\n",
       " 'amphibians',\n",
       " 'reptiles',\n",
       " 'published',\n",
       " 'served',\n",
       " 'reviewed',\n",
       " 'researchers',\n",
       " 'years',\n",
       " 'publishing',\n",
       " 'papers',\n",
       " 'coauthored',\n",
       " 'papers',\n",
       " 'reorganized',\n",
       " 'amphibians',\n",
       " 'reptiles',\n",
       " 'proposed',\n",
       " 'changes',\n",
       " 'names',\n",
       " 'names',\n",
       " 'opted',\n",
       " 'names',\n",
       " 'names',\n",
       " 'remained',\n",
       " 'synonyms',\n",
       " 'email',\n",
       " 'articles',\n",
       " 'echinoids',\n",
       " 'appeared',\n",
       " 'roles',\n",
       " 'et',\n",
       " 'members',\n",
       " 'co',\n",
       " 'founders',\n",
       " 'began',\n",
       " 'questioning',\n",
       " 'sentences',\n",
       " 'farmers',\n",
       " 'has',\n",
       " 'described',\n",
       " 'attained',\n",
       " 'became',\n",
       " 'players',\n",
       " 'dies',\n",
       " 'succeeded',\n",
       " 'concludes',\n",
       " 'awarded',\n",
       " 'protests',\n",
       " 'deaths',\n",
       " 'forces',\n",
       " 'defeated',\n",
       " 'armies',\n",
       " 'troops',\n",
       " 'repulsed',\n",
       " 'assaults',\n",
       " 'issued',\n",
       " 'expropriating',\n",
       " 'owned',\n",
       " 'reserves',\n",
       " 'facilities',\n",
       " 'owned',\n",
       " 'released',\n",
       " 'described',\n",
       " 'deadliest',\n",
       " 'nightclub',\n",
       " 'deaths',\n",
       " 'anniversaries',\n",
       " 'email',\n",
       " 'terms',\n",
       " 'principles',\n",
       " 'restored',\n",
       " 'macularia',\n",
       " 'pictures',\n",
       " 'areas',\n",
       " 'projects',\n",
       " 'resources',\n",
       " 'activities',\n",
       " 'areas',\n",
       " 'questions',\n",
       " 'using',\n",
       " 'languages',\n",
       " 'librarians',\n",
       " 'volunteers',\n",
       " 'questions',\n",
       " 'subjects',\n",
       " 'updates',\n",
       " 'articles',\n",
       " 'releases',\n",
       " 'discussions',\n",
       " 'including',\n",
       " 'areas',\n",
       " 'issues',\n",
       " 'policies',\n",
       " 'projects',\n",
       " 'hosted',\n",
       " 'hosts',\n",
       " 'projects',\n",
       " 'software',\n",
       " 'coordination',\n",
       " 'textbooks',\n",
       " 'manuals',\n",
       " 'quotations',\n",
       " 'tools',\n",
       " 'languages',\n",
       " 'largest',\n",
       " 'articles',\n",
       " 'articles',\n",
       " 'articles',\n",
       " 'nynorsk',\n",
       " 'https',\n",
       " 'wikipedia',\n",
       " 'org',\n",
       " 'php',\n",
       " 'oldid',\n",
       " 'tools',\n",
       " 'events',\n",
       " 'changes',\n",
       " 'changes',\n",
       " 'pages',\n",
       " 'projects',\n",
       " 'bokm',\n",
       " 'nynorsk',\n",
       " 'srpski',\n",
       " 'edited',\n",
       " 'terms',\n",
       " 'using',\n",
       " 'trademark']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "def unknown(url):\n",
    "    raw = remove_markup(url)\n",
    "    lowercase_words = re.findall(r\"\\b[a-z]+\", raw)\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    return [w for w in lowercase_words if w not in english_vocab]\n",
    "\n",
    "unknown(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "separated-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home - BBC News\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "   Accessibility  Skip to  Accessibility Help BBC  Notifications       CBBCC       Menu  Search the BBCSearch the BBC  \n",
      "\n",
      "BBC  News    Home     US &  UK    Entertainment &   In  Reality  World News TVNewsbeatLong  More More   Home   Coronavirus  Your Coronavirus    World      Latin  Middle  US &  UKUK   N.    Local   Business  Market  New  New Tech    Technology of   CEO  Global Car  Business of     Entertainment &   Health   In  Reality  World News TVNewsbeatLong Reads\n",
      "\n",
      "BBC News Home\n",
      "BreakingBreaking  Close breaking news\n",
      "Latest  Most  Skip to most  Latest  Most Read\n",
      "\n",
      "\n",
      "\n",
      "Top  Angry exchanges at US and China talks in  The first high-level meeting of the new US administration and Beijing opened with sharp  6h6 hours  US &  Angry exchanges at US and China talks in  The first high-level meeting of the new US administration and Beijing opened with sharp  6h6 hours  US &  Related   Blinken opens talks with critical  What the US wants from the  A new 'Cold War' in US-China ties? Who are the victims of Atlanta spa  Six of the eight people killed were Asian women. Here's what we know so far about the  14m15 minutes  US &  Paris set for lockdown as France fears third  The French capital and various other areas will have movement restricted as cases  4h4 hours   Video 3 minutes 16  Video 3 minutes 16  3:16Video 3 minutes 16  He slashed me from cheek-to-cheek'Asian Americans across the US have faced a surge in hate crimes during the  14h14 hours  US &  Joe Biden's 'big problem' at the US  The president is confronting his the first political and policy crisis - on  16h16 hours  US &  The woman who is Tanzania's new  Vice-President Samia Suluhu Hassan steps up after the death of President John  12m13 minutes   Canadian spy trial in China ends without  Michael Spavor's case is part of a diplomatic spat between China and the US and  3h3 hours     Epidemic still shrinking in UK, R number  The figure shows the average number of people someone with Covid goes on to infect and remains below  UKChina hails granny who fought off attacker in USThe 76-year-old was waiting to cross the street in San Francisco when she was punched, reports  7h7 hours   Dozens change name to 'salmon' to get sushi  Officials in Taiwan plead with people to stop changing their names to take  1da day   Judge denies request to move Chauvin  Lawyers for Mr Chauvin, accused of killing George Floyd, had argued that the jury could be  1han hour  US &  Dozens change name to 'salmon' to get sushi  Officials in Taiwan plead with people to stop changing their names to take  1da day   Judge denies request to move Chauvin  Lawyers for Mr Chauvin, accused of killing George Floyd, had argued that the jury could be  1han hour  US &  Video 7 minutes 15  Video 7 minutes 15  7:15Video 7 minutes 15  Why are schools under attack in  Parts of Nigeria are seeing unprecedented mass school abductions that have left at least one student  2h2 hours   Heavy rain unearths ancient Greek bull  A bronze statuette believed to be at least 2,500 years old is found near the ancient site of  2m3 minutes   Goldman Sachs bankers ask for 80-hour week  First-year analysts have reported 95-hour working weeks plus poor physical and mental  1h39 minutes  Business\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Must  A millionaire’s plan to create a local  How to  BBC World News TVThe latest global news, sport, weather and   Listen   BBC World Service  Stories from around the    Tornadoes rip through southern USWho this Japanese biker actually turned out to  Weekly quiz: Who's made headlines this awards  Africa's top shots: Zebras crossing and sand  Death of a Zulu king: 'He is planted, not buried'\n",
      "Most  1 He slashed me from cheek-to-cheek'2VideoWhy Australian women are saying 'enough is  3 Tornadoes rip through southern US4VideoOne-minute World  5 Iceland shaken by 50,000 earthquakes in three weeks\n",
      "Full  The clanking sound of Perseverance's  A Bollywood star and the battle for Indian  The 'insane' money in trading collectible  Why is India struggling to meet global vaccine  The cautionary tale of the president who denied  From boom to bust - why lockdown hasn't led to more  Asia's richest man, a bomb scare and a murder\n",
      "\n",
      "Long  The days when the country edged close to  The art dealer, the £10m Benin Bronze and the  Army of volunteers restore lost photos after  Finding the babies who were given  Abducted, shackled and forced to marry at 12\n",
      "Most  1Angry exchanges at US and China talks in  2Goldman Sachs bankers ask for 80-hour week  3China hails granny who fought off attacker in US4Canadian spy trial in China ends without  5US actor Armie Hammer accused of  6Peloton warning after ‘tragic’ child  7Paris set for lockdown as France fears third  8US to send 4m vaccine doses to Canada and  9The woman who is Tanzania's new  10Japanese biker wows internet with his face editing\n",
      "Around the BBCThe invention that ignited game  BBC  The core work skill many of us  BBC  Why people criticised Jane  BBC  Is the nude selfie a new art  BBC  We went troll hunting in  BBC  The human right that benefits  BBC  Why you trust your colleagues less  BBC Worklife\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SportSee  Liverpool face Real Madrid in Champions League - full quarter and semi-final  1h43 minutes  European Football  Man Utd face Granada, Arsenal play Slavia Prague in Europa  2h2 hours  European Football    Live text from day four of the 2021 Cheltenham  Horse  Rangers won't let Kamara 'be yet another statistic' as they demand Uefa racism  3h3 hours  European  Van Barneveld collapses at PDC  1ma minute   UFC champion Nurmagomedov '100% officially  7h7 hours  Mixed Martial  Bullies, weight loss and a mother's analysis - Okolie set for cruiserweight world-title  3h3 hours  Boxing\n",
      "Find us  News daily  Get news from the BBC in your inbox each weekday  Mobile  Find out more about our BBC News  Get in  Email us at haveyoursay@bbc.co.ukSend an SMS or MMS to +44 7624 800100Follow Have Your Say on  Why you can trust BBC News\n",
      "News     Home   Coronavirus  Your Coronavirus    World      Latin  Middle  US &  UKUK   N.    Local   Business  Market  New  New Tech    Technology of   CEO  Global Car  Business of     Entertainment &   Health   In  Reality  World News TVNewsbeatLong Reads\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Explore the BBCHomeNewsSportWeatheriPlayerSoundsCBBCCBeebiesFoodBitesizeArtsTasterLocalThreeTerms of  About the BBCPrivacy   Accessibility  Parental  Contact the BBCGet Personalised  Copyright © 2021 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.     \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = remove_markup(\"https://news.bbc.co.uk/\")\n",
    "# p = r\"[A-Za-z][a-z]+(?=[A-Z])\"\n",
    "p = r\"[A-Za-z][a-z'.?]+(?=[A-Z0-9])\"\n",
    "words = []\n",
    "for word in raw.split(\" \"):\n",
    "    if re.match(p, word):\n",
    "        split_word = re.split(p, word)\n",
    "        for part in split_word:\n",
    "            words.append(part)\n",
    "    else:\n",
    "        words.append(word)\n",
    "res = \" \".join(words)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wrapped-rally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp = r\"do|n't\"\n",
    "re.findall(regexp, \"don't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "metropolitan-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$up3r c00|5w33t! I 4m th3 |33t h4xx0r5w33t!\n"
     ]
    }
   ],
   "source": [
    "def leetspeak(s):\n",
    "    s = re.sub(\"e\", \"3\", s)\n",
    "    s = re.sub(\"o\", \"0\", s)\n",
    "    s = re.sub(\"l\", \"|\", s)\n",
    "    s = re.sub(\"s\", \"5\", s)\n",
    "    s = re.sub(\"^5\", \"$\", s)\n",
    "    s = re.sub(\"\\.\", \"5w33t!\", s)\n",
    "    s = re.sub(\"ate\", \"8\", s)\n",
    "    s = re.sub(\"a\", \"4\", s)\n",
    "    return s\n",
    "\n",
    "s = \"super cool. I am the leet haxxor.\"\n",
    "print(leetspeak(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "paperback-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ixnay\n",
      "appleyay\n"
     ]
    }
   ],
   "source": [
    "def pig_latin_word(w):\n",
    "    vowel = re.compile(\"a|e|i|o|u\", re.IGNORECASE)\n",
    "    start = w[0]\n",
    "    if not re.match(vowel, start):\n",
    "        return w[1:] + start + \"ay\"\n",
    "    else:\n",
    "        return w + \"yay\"\n",
    "        \n",
    "    return pig\n",
    "\n",
    "print(pig_latin_word(\"nix\"))\n",
    "print(pig_latin_word(\"apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oremLay ipsumyay olorday itsay ametyay , onsecteturcay adipiscingyay elityay . Utyay edsay efficituryay uruspay , edsay ulputatevay ortortay .\n"
     ]
    }
   ],
   "source": [
    "def pig_latin_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for i in range(len(words)):\n",
    "        if re.match(r\"\\w+\", words[i]):\n",
    "            words[i] = pig_latin_word(words[i])\n",
    "    return \" \".join(words)\n",
    "\n",
    "lorem = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut sed efficitur purus, sed vulputate tortor.\"\n",
    "print(pig_latin_text(lorem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "julian-feelings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ickquay\n",
      "ellowyay\n",
      "tylesay\n",
      "Oremlay ipsumyay olorday itsay ametyay , onsecteturcay adipiscingyay elityay . Utyay edsay efficituryay uruspay , edsay ulputatevay ortortay .\n"
     ]
    }
   ],
   "source": [
    "def improved_pig_latin_word(w):\n",
    "    vowel = re.compile(\"a|e|i|o|u\", re.IGNORECASE)\n",
    "    start = w[0]\n",
    "    if not re.match(vowel, start):\n",
    "        if re.match(r\"^qu\", w):\n",
    "            return w[2:] + \"quay\"\n",
    "        return w[1:] + start + \"ay\"\n",
    "    else:\n",
    "        return w + \"yay\"\n",
    "        \n",
    "    return pig\n",
    "\n",
    "print(improved_pig_latin_word(\"quick\"))\n",
    "print(improved_pig_latin_word(\"yellow\"))\n",
    "print(improved_pig_latin_word(\"style\"))\n",
    "\n",
    "def improved_pig_latin_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    s = \"\"\n",
    "    for i in range(len(words)):\n",
    "        if re.match(r\"\\w+\", words[i]):\n",
    "            caps = [words[i][j].isupper() for j in range(len(words[i]))]\n",
    "            pig = improved_pig_latin_word(words[i])\n",
    "            letters = []\n",
    "            for j in range(len(pig) - 3):\n",
    "                if caps[j]:\n",
    "                    letters.append(pig[j].upper())\n",
    "                else:\n",
    "                    letters.append(pig[j].lower())\n",
    "            \n",
    "            words[i] = \"\".join(letters) + pig[-3:].lower()\n",
    "    return \" \".join(words)\n",
    "\n",
    "print(improved_pig_latin_text(lorem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cardiac-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  e  i  o  u  á  é  í  ó  ö  ú  ü  ő  ű \n",
      "a 46 13  4 14  2 16  0  2  3  0  0  0  0  0 \n",
      "e  2 80 24  3  0  3 22  5  0  4  0  6 25  2 \n",
      "i  3 16  0  0  0  1  3  0  0  0  0  0  5  0 \n",
      "o  7  0  0  0  0 15  2  2  2  0  1  0  0  0 \n",
      "u  3  0  0  1  0  0  0  0  2  0  0  0  0  0 \n",
      "á 22  1  1  9  2 10  0  0  3  0  0  0  0  0 \n",
      "é  0 26  5  0  0  0  7  1  0  0  0  0  1  1 \n",
      "í  2  3  1  0  0  1  2  0  0  0  0  0  0  0 \n",
      "ó  1  0  0  0  0  0  0  0  0  0  0  0  0  0 \n",
      "ö  0  7  0  0  0  0  7  0  0  0  0  0  0  0 \n",
      "ú  0  0  0  0  0  5  0  0  1  0  0  0  0  0 \n",
      "ü  0  4  0  0  0  0  2  0  0  2  0  0  0  2 \n",
      "ő  4  2  1  3  0  0  0  0  0  1  0  0  0  0 \n",
      "ű  0  1  0  0  0  0  0  0  0  2  0  0  0  0 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "hungarian = udhr.words(fileids=\"Hungarian_Magyar-UTF8\")\n",
    "vowels = r\"[eéiíöőüűaáoóuú]\"\n",
    "\n",
    "vowel_bigrams = []\n",
    "for word in hungarian:\n",
    "    if re.match(vowels, word):\n",
    "        vbs_in_word = list(nltk.bigrams(re.findall(vowels, word)))\n",
    "        for vb in vbs_in_word:\n",
    "            vowel_bigrams.append(vb)\n",
    "\n",
    "fdist = nltk.ConditionalFreqDist(vowel_bigrams)\n",
    "fdist.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "finnish-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "ehh haahhhh h hh hhe ha haaa aaaeheaaa e ha e eahhahhahhaeaheehe h eehh hh hh  ehha  hha aehhh hhehhahhehheah ha h eahhahee  aeh ehhahe heeaehhah ahehahhe eeah h ehha h a ee  h hea ehhaeh  a   hheheh hh a eh a  haa ehehhhe aeahaeh eheeh hehaheheeehe ehhhehhaeehh h haehehheae aeaa  ha eh ahhh a h e hah h ah ehaa ehaah   e ea hhh ahh hahh  e ha  hehhhhhhah hhea a e ahe e ahhheaeae hha ahheeh hehhhaha hhhhhaeea hhheheheahhheh  a aaehheeeah  heh aa  h  eeheehheeeaaa eahh hhaeheeehaehae aeeheheahhhhh\n",
      "After:\n",
      "ehh haahhhh h hh hhe ha haaa aaaeheaaa e ha e eahhahhahhaeaheehe h eehh hh hh ehha hha aehhh hhehhahhehheah ha h eahhahee aeh ehhahe heeaehhah ahehahhe eeah h ehha h a ee h hea ehhaeh a hheheh hh a eh a haa ehehhhe aeahaeh eheeh hehaheheeehe ehhhehhaeehh h haehehheae aeaa ha eh ahhh a h e hah h ah ehaa ehaah e ea hhh ahh hahh e ha hehhhhhhah hhea a e ahe e ahhheaeae hha ahheeh hehhhaha hhhhhaeea hhheheheahhheh a aaehheeeah heh aa h eeheehheeeaaa eahh hhaeheeehaehae aeeheheahhhhh\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomtext():\n",
    "    s = \"\"\n",
    "    for i in range(500):\n",
    "        s = s + random.choice(\"aehh \")\n",
    "    return s\n",
    "\n",
    "non_normal = \"\".join(randomtext())\n",
    "print(\"Before:\")\n",
    "print(non_normal)\n",
    "normal = \" \".join(re.split(r\"\\s+\", non_normal))\n",
    "print(\"After:\")\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abroad-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were trying to create a text to speech system, it might be best to split it into nine words since the TTS reading is going to be nine words long. If, however, we simply wanted to extract the expressions from the text and evaluate them, then it might make more sense to treat them as if they consisted of three words - one for the first operand, another for the operator, and a third for the second operand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "naked-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure: 4.0841684990890705\n",
      "belles_lettres: 10.987652885621749\n",
      "editorial: 9.471025332953673\n",
      "fiction: 4.9104735321302115\n",
      "government: 12.08430349501021\n",
      "hobbies: 8.922356393630267\n",
      "humor: 7.887805248319808\n",
      "learned: 11.926007043317348\n",
      "lore: 10.254756197101155\n",
      "mystery: 3.8335518942055167\n",
      "news: 10.176684595052684\n",
      "religion: 10.203109907301261\n",
      "reviews: 10.769699888473433\n",
      "romance: 4.34922419804213\n",
      "science_fiction: 4.978058336905399\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()\n",
    "\n",
    "def ARI(category):\n",
    "    words = brown.words(categories=category)\n",
    "    sents = brown.sents(categories=category)\n",
    "    avg_letters = sum([len(w) for w in words]) / len(words)\n",
    "    avg_words = sum([len(s) for s in sents]) / len(sents)\n",
    "    return (4.71 * avg_letters) + (0.5 * avg_words) - 21.43\n",
    "\n",
    "for cat in brown.categories():\n",
    "    print(f\"{cat}: {ARI(cat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fitting-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['univers', 'declar', 'of', 'human', 'right', 'preambl', 'wherea', 'recognit', 'of', 'the', 'inher', 'digniti', 'and', 'of', 'the', 'equal', 'and', 'inalien', 'right', 'of', 'all', 'member', 'of', 'the', 'human', 'famili', 'is', 'the', 'foundat', 'of', 'freedom', ',', 'justic', 'and', 'peac', 'in', 'the', 'world', ',', 'wherea', 'disregard', 'and', 'contempt', 'for', 'human', 'right', 'have', 'result', 'in', 'barbar', 'act', 'which', 'have', 'outrag', 'the', 'conscienc', 'of', 'mankind', ',', 'and', 'the', 'advent', 'of', 'a', 'world', 'in', 'which', 'human', 'be', 'shall', 'enjoy', 'freedom', 'of', 'speech', 'and', 'belief', 'and', 'freedom', 'from', 'fear', 'and', 'want', 'ha', 'been', 'proclaim', 'as', 'the', 'highest', 'aspir', 'of', 'the', 'common', 'peopl', ',', 'wherea', 'it', 'is', 'essenti', ',', 'if']\n",
      "\n",
      "['univers', 'decl', 'of', 'hum', 'right', 'preambl', 'wherea', 'recognit', 'of', 'the', 'inh', 'dign', 'and', 'of', 'the', 'eq', 'and', 'ina', 'right', 'of', 'al', 'memb', 'of', 'the', 'hum', 'famy', 'is', 'the', 'found', 'of', 'freedom', ',', 'just', 'and', 'peac', 'in', 'the', 'world', ',', 'wherea', 'disregard', 'and', 'contempt', 'for', 'hum', 'right', 'hav', 'result', 'in', 'barb', 'act', 'which', 'hav', 'out', 'the', 'conscy', 'of', 'mankind', ',', 'and', 'the', 'adv', 'of', 'a', 'world', 'in', 'which', 'hum', 'being', 'shal', 'enjoy', 'freedom', 'of', 'speech', 'and', 'believ', 'and', 'freedom', 'from', 'fear', 'and', 'want', 'has', 'been', 'proclaim', 'as', 'the', 'highest', 'aspir', 'of', 'the', 'common', 'peopl', ',', 'wherea', 'it', 'is', 'ess', ',', 'if']\n"
     ]
    }
   ],
   "source": [
    "# The Porter stemmer seems to select better stems when the stem word is longer. For example the Porter's \"inalien\" (still not a real word, but closer) for \"inalienable\" vs the Lancaster's \"ina\" (unrecognizable). \n",
    "# Likewise, the Lancaster stemmer seems to select slightly better for shorter stems. See Lancaster's \"found\" vs. Porter's \"foundat\" for \"foundation\".\n",
    "en_udhr = udhr.words(fileids='English-Latin1')\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print([porter.stem(t) for t in en_udhr[:100]])\n",
    "print()\n",
    "print([lancaster.stem(t) for t in en_udhr[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "orange-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]\n",
      "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more',\n",
    "'is', 'said', 'than', 'done', '.']\n",
    "\n",
    "lengths = []\n",
    "for w in saying:\n",
    "    lengths.append(len(w))\n",
    "print(lengths)\n",
    "lengths = [len(w) for w in saying]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "multiple-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newly', 'formed', 'bland', 'ideas', 'are', 'inexpressible', 'in', 'an', 'infuriating', 'way']\n",
      "eoldrnnnna\n",
      "newly formed bland ideas are inexpressible in an infuriating way\n",
      "['an', 'are', 'bland', 'formed', 'ideas', 'in', 'inexpressible', 'infuriating', 'newly', 'way']\n"
     ]
    }
   ],
   "source": [
    "silly = 'newly formed bland ideas are inexpressible in an infuriating way'\n",
    "bland = silly.split(\" \")\n",
    "print(bland)\n",
    "print(\"\".join([w[1] for w in bland]))\n",
    "print(\" \".join(bland))\n",
    "print(sorted(bland))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "breeding-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "8\n",
      "['newly', 'formed', 'bland', 'ideas', 'are', 'inexpressible']\n"
     ]
    }
   ],
   "source": [
    "print(\"inexpressible\".index(\"re\"))\n",
    "words = bland\n",
    "print(words.index(\"infuriating\"))\n",
    "phrase = bland[:bland.index(\"in\")]\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coastal-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asia\n",
      "Chiapas\n",
      "Antarctica\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_of_place_names\"\n",
    "html = request.urlopen(url).read().decode(\"utf8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "dictionary = {}\n",
    "for table in tables:\n",
    "    rows = table.find_all(\"tr\")\n",
    "    td_rows = [row for row in rows if not row.th]\n",
    "    for row in td_rows:\n",
    "        tds = [e for e in row.contents if e != \"\\n\"]\n",
    "        if len(tds) > 1:\n",
    "            state = tds[0].string\n",
    "            adj = tds[1].string\n",
    "            if state and adj:\n",
    "                dictionary[adj] = state\n",
    "\n",
    "print(dictionary[\"Asian\"])\n",
    "print(dictionary[\"Chiapan\"])\n",
    "print(dictionary[\"Antarctic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elementary-strap",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sub in module re:\n",
      "\n",
      "sub(pattern, repl, string, count=0, flags=0)\n",
      "    Return the string obtained by replacing the leftmost\n",
      "    non-overlapping occurrences of the pattern in string by the\n",
      "    replacement repl.  repl can be either a string or a callable;\n",
      "    if a string, backslash escapes in it are processed.  If it is\n",
      "    a callable, it's passed the Match object and must return\n",
      "    a replacement string to be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "help(re.sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "premier-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Richard Stallman's Personal Site\n",
      "\n",
      "\n",
      "I\n",
      "continue to be the Chief GNUisance of the GNU Project.\n",
      "This is my long-term commitment and I plan to continue.\n",
      "\n",
      "\n",
      "    If you participate in the commercial ritual of end-of-the-year\n",
      "presents, please avoid the digital products that would mistreat\n",
      "the people you give them to.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      "Humorous\n",
      "Bio |\n",
      " |\n",
      "Empire of the\n",
      "Megacorporations |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Site search: <input type=\"text\" size=\"30\"\n",
      "name=\"term\">\n",
      "\n",
      " style=\"font-family: monospace\"\n",
      "href=\"site-search/index.html\">advanced\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What's bad about:\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " meetup.com has the same injustices as eventbrite.com\n",
      "and they share one page \n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      " |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I will give a virtual talk about A Free Digital Society,\n",
      "hosted by the University of Limerick Computer Society.\n",
      "March 10 at 19h00 Irish time.\n",
      "\n",
      "Everyone is welcome to attend, but the streaming capacity\n",
      "is limited.  So please email talks (at) skynet (dot)\n",
      "ie with \"rms Interest\" or \"Richard Stallman Interest\"\n",
      "in the Subject field, and the hosts will email you the\n",
      "URL.  If there is no room for you, you can watch the\n",
      "recording which will be announced later.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " for the most recent\n",
      "political notes and new material.\n",
      "\n",
      "This is the personal web site of Richard Stallman.\n",
      "The views expressed here are my personal views, not those of\n",
      "the  or\n",
      "the \n",
      "For the sake of separation, this site has always been\n",
      "hosted elsewhere and managed separately.\n",
      "\n",
      "\n",
      "If you want to send me GPG-encrypted mail, do not trust key\n",
      "servers!\n",
      "Some of them have phony keys under my name and email address,\n",
      "made by someone else as a trick.\n",
      "See  for my real key.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Don't watch TV\n",
      "coverage of Covid-19!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vote for Sanders .\n",
      "It is important to win him more delegates even though he won't win the\n",
      "nomination that way.  Besides, if Biden's various problems knock him\n",
      "out, Sanders might yet be nominated.\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "Participate in a  on Fridays.\n",
      "\n",
      "Join a .\n",
      "\n",
      "This page is made by scraping Fridays for Future so you can get the\n",
      "information without running any Javascript code.  I would be very glad\n",
      "if they made the information on their own site accessible\n",
      "from the Free World; then we could simply refer people to their site\n",
      "and do without the scraping etc.\n",
      "\n",
      "\n",
      "\n",
      "I am looking for a few more volunteers to help install new\n",
      "political notes on the site. If you'd like to help me in this\n",
      "way, please write to rms at gnu period org.\n",
      "\n",
      "\n",
      "\n",
      "Is your bank pressuring you to use biometric ID?\n",
      "If so, please write to rms at gnu dot org.\n",
      "It could be useful if you document what is happening.\n",
      "\n",
      "\n",
      "\n",
      "Please\n",
      "\n",
      "donate to the Free Software Foundation to support its work\n",
      "for your freedom.\n",
      "\n",
      "\n",
      "\n",
      "\"They\" is plural &mdash;\n",
      "for singular antecedents, use \n",
      "singular gender-neutral pronouns.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The largest part of the site is the\n",
      ", and they\n",
      "are typically updated every day.\n",
      "\n",
      "\n",
      "(in India) make and sell buttons that say, \"DON'T BE\n",
      "TRACKED&nbsp;&nbsp;PAY CASH\", in English and/or a local\n",
      "language, to resist the campaign against\n",
      "cash.  Talk with a local company that makes buttons, buy a\n",
      "batch of 50 to 500 buttons for a quantity price, then sell\n",
      "them for 2 or 3 times that price.\n",
      "If you know of a bank in the US that charges less than ten dollars for\n",
      "incoming wire transfers, please tell me about it.\n",
      "\n",
      "I can't do online banking, since most US banks require customers to\n",
      "run nonfree apps or Javascript code for that, so I would need to open\n",
      "an account in some other way.  Therefore, it would be best if the bank\n",
      "had an office in the Boston area.  However, I'd be interested in whatever\n",
      "banks you can recommend even if they are not near me.\n",
      "send me examples of how proprietary programs have been\n",
      "designed to be addictive.\n",
      "\n",
      "send me examples of how proprietary programs have been\n",
      "designed to cause programmed obsolescence of products.\n",
      "Write a program to scrape fridaysforfutureusa.org\n",
      "and post the practical info about finding climate strike\n",
      "rallies on another web site which makes that information\n",
      "accessible without running JavaScript code.\n",
      "\n",
      "I would like to publicize these events, as well as attend sometimes\n",
      "myself.\n",
      "get info about Delta face recognition.\n",
      "\n",
      "Delta\n",
      "Airlines' web\n",
      "site says clearly that using face\n",
      "recognition to for departures is optional.\n",
      "\n",
      "\n",
      "However, there are reports that in the airport they cover this up.\n",
      "\n",
      "\n",
      "Would someone flying on Delta out of Atlanta please record the\n",
      "announcements about face recognition for checkin and\n",
      "boarding?  And what the checkin agent says to you about\n",
      "rejecting the face recognition.  Also please take photos of\n",
      "any signs that talk about the matter.  Then please send me\n",
      "email about what you saw/heard.\n",
      "\n",
      "develop a Firefox front end to search the Internet Archive\n",
      "with Javascript disabled (or LibreJS active).\n",
      "find articles about games that lure and pressure users\n",
      "into spending a lot of money on competitive advantages, or letting\n",
      "their children do so.  I've concluded this is a form of malicious\n",
      "functionality, and I want to make a list to add to\n",
      "https://gnu.org/malware/.  If you know of an article, please email me\n",
      "the URL.\n",
      "browse various sites and show me\n",
      "items that I ought to see and link to.  If you would like to help me\n",
      "in this way, please write to rms at gnu dot o r g.\n",
      "write site-specific Firefox extensions\n",
      "or local scripts to operate specific web sites.\n",
      "help\n",
      "\n",
      "maintain and operate\n",
      "experiment to find good ways to attach\n",
      "fruits to a \n",
      "help web sites put free licenses\n",
      "on their Javascript code.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " src=\"flag_set_vectorized.png\"\n",
      "alt=\"[America Means Civil Liberties / Patriotism Means Protecting\n",
      "Them / www.aclu.org/safefree ]\" style=\"margin-left:-6px;\">\n",
      "\n",
      "graphic by Susan Henson\n",
      "Americans, you may wish to copy this icon to your own page, as a\n",
      "way of showing what patriotism means to you.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "From now on, please put these numbers at the end of every urgent note\n",
      "that involves calling US congresscritters or senators.\n",
      "\n",
      "\n",
      "\n",
      "From now on, please put this line at the end of urgent notes\n",
      "about calling the White House.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Format for date: Expires DD Month YYYY\n",
      "Variations of this aren't correctly read by the program that tallies expired urgent notes. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on the Senate to .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on the National Marine Fisheries Service to slow\n",
      "ships to .\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on the FTC to  to\n",
      "fix the price of insulin.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Biden and the Senate to appoint a progressive\n",
      "commissioner to the FCC, and soon.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on your congresscritter to sign the\n",
      "Lee-Pocan-Auchincloss letter to reduce military spending.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Congress to cancel the ship-launched cruise\n",
      "missile.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Congress to support the Break Free From Plastic\n",
      "Pollution Act of 2021.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Biden to put an \n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Biden and Congress not to make Rahm Emanuel an\n",
      "ambassador.\n",
      "\n",
      "Here are .\n",
      "\n",
      "To sign without running  code\n",
      "from the web site, use the .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Congress and Biden to do their utmost to support\n",
      "unionization at Amazon.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on the Senate to reject the Menendez-Graham\n",
      "letter, which would obstruct resuming the non-nuclear deal with Iran.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Congress to .\n",
      "which would terrify companies into censoring who-knows-what.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "US citizens: call on Congress to , which would\n",
      "pressure Internet platforms to censor very strictly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Listen to the \n",
      "\n",
      "of ,\n",
      "a protest song written in Spanish.  The recording is in\n",
      "Ogg Vorbis format.  To install an Ogg Vorbis player,\n",
      "see \n",
      "the FSF's Ogg Players page.\n",
      "\n",
      "\n",
      " Only keep the 4 most recent items here.  After that move to --\n",
      "-- ~/public_html/there-ought-to-be-a-law.html \n",
      "\n",
      "\n",
      "\n",
      "This file is displayed on the index.html page of stallman.org and shouldn't take up\n",
      "too much page space so four texts is the current desired limit. New texts should be added\n",
      "to this file and the oldest from here moved to there-ought-to-be-a-law.html. This file is\n",
      "included at the top of there-ought-to-be-a-law.html so these texts are listed in the master\n",
      "list.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "It should be a crime to knowingly  inside\n",
      "a building or vehicle.\n",
      "\n",
      "\n",
      "\n",
      "*The pandemic has taken  to the next level.*\n",
      "\n",
      "The extreme of this is represented by the Amazon warehouse,\n",
      "where a worker's every move is controlled by the computer system.\n",
      "This is one of .\n",
      "\n",
      "Unfortunately, surveillance of workers is not limited to Amazon.  I\n",
      "think states should pass laws to limit surveillance of workers.  It\n",
      "should cover independent contractors as well as employees.\n",
      "\n",
      "The law should completely forbid demanding that workers run any\n",
      "specific software on their own computers (keep in mind that portable\n",
      "phones are computers); the employer who wants that must furnish\n",
      "the computer at no charge.\n",
      "\n",
      "\n",
      "\n",
      "A hundred years ago, having your face photo circulated as a suspect\n",
      "could  &mdash; for instance, making it impossble to get a job.\n",
      "\n",
      "Now it can cause you to be arrested randomly for walking down the street.\n",
      "\n",
      "If stores use face recognition inside the store, they should not be\n",
      "allowed to use photos for matching against people in the store\n",
      "except for photos they have taken in that store, and photos\n",
      "of people convicted of theft and fraud.\n",
      "\n",
      "\n",
      "\n",
      "The corrupter has , who was convicted for lying to the FBI about what he did for the corrupter.\n",
      "\n",
      "This is a corrupt practice.  I think we need to limit the president's\n",
      "power to pardon so that presidents cannot do this in the future.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "More items where there\n",
      "ought to be a law.\n",
      "\n",
      "\n",
      "\n",
      "Here are some\n",
      "\n",
      "quotations that I particularly like.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Political\n",
      "Notes and News Items)\n",
      "\n",
      " height=\"2200\" width=\"100%\" frameborder=\"0\" scrolling=\"auto\"\n",
      "src=\"https://stallman.org/rss/static/recent-pol-notes.html\">If you can see\n",
      "this, your\n",
      "browser does not support iframes.  You can see the pol-notes on\n",
      "the \n",
      "current pol-notes\n",
      "page\n",
      "\n",
      "(You may need to scroll down for more text if there is blank space in\n",
      "this column.)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The four factors of the apocalypse:\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;global heating, global hating,\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;global eating, global mating.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " src=\"/images/so-many-candidates-small.jpg\"\n",
      "alt=\"So Many Candidates\">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "src=\"/no-facebook-svg.png\"\n",
      "alt=\"Not f'd. You won't find us on Facebook\"\n",
      "width=\"200\">\n",
      "\n",
      "Copy  (courtesy of R.Siddharth)\n",
      "to express your rejection of Facebook.\n",
      "\n",
      "\n",
      " Template for plugs:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*Description*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Republican Election\n",
      "Rigging Tactics\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Why everyone has a reason to fear\n",
      "massive surveillance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I'm looking for people who would\n",
      "like to launch and run a petition where people will publicly\n",
      "state that if the UK starts fingerprinting air travelers,\n",
      "they will not fly out of UK airports.  The site should\n",
      "display the names and cities of signers.  Please write to rms\n",
      "at gnu.org if you are interested.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Is anyone interested in taking\n",
      "a leadership role in a campaign to encourage people to remove\n",
      "passwords from their WiFi hubs?  I am too overloaded to do\n",
      "it, but I hope to inspire someone else.  Please write to rms\n",
      "at gnu.org.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Non-oppressive Commercial\n",
      "E-books\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Facebook's <a\n",
      "href=\"http://www.guardian.co.uk/commentisfree/cifamerica/2011/jun/14/facebook-facial-recognition-software\">face\n",
      "recognition demonstrates a threat to everyone's privacy. I\n",
      "therefore ask people not to put photos of me on Facebook; you\n",
      "can do likewise.\n",
      "\n",
      "Facebook is bad for\n",
      "many other reasons as well.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'd like to make a list of countries that do not require a national\n",
      "identity card, and have no plans to adopt one. If you live in or have\n",
      "confirmed knowledge of such a country, please send email to rms at\n",
      "gnu.org.\n",
      "\n",
      "\n",
      "Here's my list of countries with no national ID cards\n",
      "and no plans for one: Australia, Canada, New Zealand, UK.\n",
      "Australia's previous government tried to\n",
      "institute national ID cards, but the Labor government dropped\n",
      "the plan.\n",
      "\n",
      "India has mostly finished imposing a national biometric ID number\n",
      "in a grand act of oppression.\n",
      "\n",
      "\n",
      "Switzerland has national ID cards which are optional,\n",
      "but they or some other government ID card are needed for some purposes.\n",
      "\n",
      "Iceland doesn't have ID cards as such, but they\n",
      "have ID numbers that citizens are forced to use frequently.\n",
      "For example, the national ID number is often required to\n",
      "rent a video or use a gym.\n",
      "\n",
      "\n",
      "\n",
      "Denmark issues non-photo ID cards with a \"person number\", and many\n",
      "services use this card to identify people.\n",
      "\n",
      "\n",
      "\n",
      "Norway will impose a national\n",
      "biometric\n",
      "ID card.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- national ID card by stealth.\n",
      "\n",
      "\n",
      "\n",
      "ACLU: the\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Wikipedia has a list of .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Stay away from certain countries because of their\n",
      "bad\n",
      "immigration policies.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Avoid flight connections in these airports because\n",
      "of their\n",
      "\n",
      "treatment of passengers.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "People often ask how I manage to continue devoting myself to\n",
      "progressive activism (such as the free software movement) for\n",
      "years without burning out.  The best way I can answer is by\n",
      "recommending a book, \n",
      "The Lifelong Activist by Hillary Rettig.\n",
      "\n",
      "I disagree with the book on one theoretical point in the last\n",
      "part of the book: we shouldn't think of political activism as\n",
      " marketing and sales, because those terms refer to\n",
      "business, and politics is something much more\n",
      "important than mere business.  However, this doesn't diminish\n",
      "the value of the book's practical advice about borrowing\n",
      "techniques from marketing and sales.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " (mostly science fiction) by my\n",
      "friend Bob Chassell who recently died.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Declaration of Richard Stallman and Euclides Mance\n",
      "on Solidarity Economy and Free Software.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As posted on his site, you can't see them in a browser\n",
      "without running some nonfree Javascript code which is apparently\n",
      "non-free.  These versions show the same text, without the obstacle.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "These are my political articles that are not related to the GNU\n",
      "operating system or free software. For GNU-related articles, see\n",
      "the GNU philosophy\n",
      "directory.\n",
      "\n",
      "You can also order copies of my\n",
      "book, Free\n",
      "Software, Free Society, 3rd edition', signed or not signed.\n",
      "\n",
      "\n",
      "\n",
      " (March 2021)\n",
      "\n",
      "\n",
      " (November 2020)\n",
      "\n",
      "\n",
      " (October 2020)\n",
      "\n",
      "\n",
      "An Extinction Rebellion activist comments about the London police\n",
      "by Clark Killick (October 2020)\n",
      "\n",
      "\n",
      " (December 2019)\n",
      "\n",
      "\n",
      "My Talk at\n",
      "Microsoft (September 2019)\n",
      "\n",
      "\n",
      " (November 2018)\n",
      "\n",
      "\n",
      " (April 2018)\n",
      "\n",
      "\n",
      "\n",
      "Better\n",
      "Genderless Pronouns in English (April 2018)\n",
      "\n",
      "\n",
      "\n",
      "A radical\n",
      "proposal to keep your personal data safe. (April 2018)\n",
      "\n",
      "\n",
      "\n",
      " (May\n",
      "2017)\n",
      "\n",
      "\n",
      "\n",
      "Anonymous\n",
      "internet payments using pay phones (Apr 2017)\n",
      "\n",
      "\n",
      "\n",
      "When people are\n",
      "conscripted\n",
      "by the DMCA into the War on Sharing. (Dec 2016)\n",
      "\n",
      "\n",
      "\n",
      "If you feel your organization needs\n",
      "a \"presence\" in\n",
      "Facebook.\n",
      "(Dec 2016)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How Much Surveillance Can Democracy Withstand?\n",
      "\n",
      "\n",
      "\n",
      "Yes, You Have\n",
      "Something to Fear. (August 2016)\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "proposal for resolving the dispute over the South China\n",
      "Sea.  (July 2016)\n",
      "\n",
      "\n",
      "\n",
      "Is\n",
      "\n",
      "duckduckgo.com partially enforcing the \"celebrity threesome\n",
      "injunction\"? (May 2016)\n",
      "\n",
      "\n",
      "\n",
      "Adapting the Marseillaise to the <a\n",
      "href=\"/articles/chant-du-29-novembre.html\">\n",
      "greatest threat to civilization.\n",
      "\n",
      "\n",
      "\n",
      "Proposing the Logo Sea\n",
      "Turtle &mdash; for Whales (October 2015)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "href=\"/articles/when-should-body-cameras-record.html\">Controlling\n",
      "When the Cameras Record (August 2015)\n",
      "\n",
      "\n",
      "\n",
      "A few\n",
      "\n",
      "words to Greece (June 2015)\n",
      "\n",
      "\n",
      "\n",
      "Fixing <a\n",
      "href=\"/articles/progressive-tax-on-business-gross-income.html\">Too\n",
      "Big To Fail (Apr 2015)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What I said about\n",
      "Hrant Dink in my talks in Turkey (Apr 2015)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Earth\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Fine government\n",
      "contractors for hiring ex-officials (Feb 2015)\n",
      "\n",
      "\n",
      "\n",
      "Suggestion to the target of a\n",
      "witch hunt (Feb 2015)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "href=\"/articles/nonexistence-not-good-or-bad.html\">Nonexistence\n",
      "(Feb 2015)\n",
      "\n",
      "\n",
      "\n",
      "The Thermocene\n",
      "Epoch (Feb 2015)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Jan 2015)\n",
      "\n",
      "\n",
      "\n",
      "My letter asking the judge not to sentence\n",
      "\n",
      "Jeremy Hammond to prison. (Jan 2015)\n",
      "\n",
      "\n",
      "\n",
      "It is a bad idea to have computers count\n",
      "the votes in public elections.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The patent system is, at best,\n",
      "\n",
      "not worth keeping.  (February 2014)\n",
      "\n",
      "\n",
      "\n",
      "Why We Need A\n",
      "State (November 2013)\n",
      "\n",
      "\n",
      "\n",
      "We can put an end to \"too big to fail\" with an\n",
      "\n",
      "innovative tax\n",
      "that also defeats corporate tax-dodging. (August 2013)\n",
      "\n",
      "\n",
      "\n",
      "  (April 1,\n",
      "2013)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fixing too big to fail (February 2013)\n",
      "\n",
      "\n",
      "\n",
      "Why\n",
      "internet music \"sale\" is a bad deal. (January 2013)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "On-line education is using a flawed Creative Commons license\n",
      "(September 2012) French\n",
      "Translation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Redistributable Scientific Publishing (April 2012)\n",
      "\n",
      "\n",
      "\n",
      "My Doctor's Office Asked me to\n",
      "Lie (August 2011)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "My criticism of the\n",
      ".\n",
      "The Venus Project is more or less the same idea.\n",
      "\n",
      "\n",
      "\n",
      "The states need to form a\n",
      "union.\n",
      "\n",
      "\n",
      "Additional\n",
      "Political Articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Those who profess to favor freedom, yet depreciate agitation, are\n",
      "men who want crops without plowing up the ground. They want rain without\n",
      "thunder and lightning. They want the ocean without the awful roar of its\n",
      "many waters. This struggle may be a moral one; or it may be a physical\n",
      "one; or it may be both moral and physical; but it must be a struggle.\n",
      "Power concedes nothing without a demand. It never did and it never\n",
      "will.\"\n",
      "\n",
      "\n",
      "\n",
      "Frederick\n",
      "Douglass, American Abolitionist,\n",
      "Letter\n",
      "to an associate, 1849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here are notes about various issues I care about, usually with links to\n",
      "more information.  The current notes are\n",
      ".  For all previous\n",
      "notes, see .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "See  for\n",
      "information on efforts to maintain links in the political notes.\n",
      "\n",
      "\n",
      "\n",
      "Political notes about the 2001 G8 summit in Genoa, Italy are being\n",
      "archived on .\n",
      "\n",
      "\n",
      "\n",
      "Richard Stallman's bio and publicity photos, and other things\n",
      "of interest to the press, have been moved to a\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " that I\n",
      "planned speeches at Israeli universities, then cancelled them.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " and\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "working on my\n",
      "laptop\n",
      ", organized by\n",
      "location, from my trips.\n",
      "\n",
      "\n",
      ",\n",
      "among those I have taken and posted here.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "More\n",
      "Photos from OSCON\n",
      "\n",
      "\n",
      "my\n",
      "\n",
      "visit to Switzerland in May 2003 (and the same\n",
      "\n",
      "photos at the original photographer's site\n",
      "\n",
      " where I slipped on icy\n",
      "ground in the airport, broke my elbow, and gave my speech by telephone from\n",
      "the hospital bed\n",
      "my <a\n",
      "href=\"/photos/greece\">trips to Greece\n",
      "\n",
      "\n",
      "In Singapore in March 2001, a <a href=\n",
      "\"parrot-love.jpg\">lovely parrot (50k jpeg) became enamored of me, while others\n",
      "\n",
      "my <a\n",
      "href=\"/photos/china/2000/RMS_in_China_2000.html\">visit to China\n",
      "in May/June 2000. I also visited Tibet unawares, because nobody told me\n",
      "that JiuZhaiGou was part of Tibetan territory annexed by China since the\n",
      "conquest\n",
      "\n",
      "my visit to Brazil: some from <a href=\n",
      "\"https://web.archive.org/web/20010613171306/http://www.cipsga.org.br/rmsinrio/\">Rio de Janeiro and some from\n",
      " where the\n",
      "Software Livre 2000 event was held.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "photo of me by Blake Livingston (may be used under CC-BY-SA).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Homeopathy debunked, and thoroughly, as pseudoscience.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Some \n",
      "\n",
      "\n",
      "\n",
      ", by Richard M. Stallman. You can listen to a performance of the song:\n",
      "\n",
      "\n",
      "Here is a variant of this song called .\n",
      "\n",
      "\n",
      "\n",
      "A song parody, , by Jefferson Carpenter.\n",
      "\n",
      "\n",
      "\n",
      "Earth\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      ", and how to spell it.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A Spanish cartoon: La Ruleta\n",
      "Espa&ntilde;ola.  <img src=\"/images/ruleta-espanola-small-alpha.png\"\n",
      "alt=\"thumbnail\" style=\"vertical-align:middle;\">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "href=\"https://web.archive.org/web/20140208062623/http://shift-reset.com/blog/2013/12/24/The%20Night%20before%20M-x-mas/\">The\n",
      "Night before M-x-mas\n",
      "\n",
      "\n",
      "\n",
      "Here I am .\n",
      "\n",
      "\n",
      "Wine\n",
      "snobs\n",
      "\n",
      "\n",
      "Here I am <a href=\n",
      "\"IMG_5884.JPG\">struggling to open a bottle of water.\n",
      "\n",
      "\n",
      "\n",
      "My application to an join Marian Henley's <a\n",
      "href=\"ex-boyfriends-list.html\">ex-boyfriends list.\n",
      "\n",
      "\n",
      "My .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(, August 2019).\n",
      "\n",
      "\n",
      "\n",
      "(New pun: \n",
      "April 2019)\n",
      "\n",
      "\n",
      "\n",
      "(New pun:  July 2019)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(New pun: Quale pesce fa\n",
      "starnutire? New 10/2018)\n",
      "\n",
      "\n",
      "\n",
      " (New 02/2016)\n",
      "\n",
      "\n",
      "\n",
      "(Now with: Wintu, Penutian, Cochiti, Taos, and Towa.)\n",
      "\n",
      "\n",
      " src=\"/graphics/saint-button.png\" alt=\"I am a\n",
      "Saint In the Church Of Emacs\">\n",
      "--Saint\n",
      "IGNUciussoon\n",
      "be officially listed by at least one person as his religion for\n",
      "census purposes.\n",
      "\n",
      "\n",
      "\n",
      "There are no godfathers in the Church of Emacs, since there are no gods,\n",
      "but you can be someone's .\n",
      "\n",
      "\n",
      ": \"I have to warn\n",
      "you that Texans have been known to have an adverse reaction to my\n",
      "personality&hellip;\"\n",
      "\n",
      "\n",
      "\n",
      "The Dalai Lama today announced the\n",
      "official release of Yellow Hat GNU/Linux.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I found a funny song about the Mickey Mouse\n",
      "Copyright Act (officially the Sonny Bono Copyright Act) which\n",
      "extended copyright retroactively by 20 years on works made as early as\n",
      "the 1920s.\n",
      "\n",
      "\n",
      "If you are a geek and read Spanish, you will love Raulito el Friki,\n",
      "who said \"Hello, world!\" immediately after he was born.  Here's\n",
      "\n",
      "an archive of this now-defunct comic strip.\n",
      "\n",
      "\n",
      "\n",
      "Sleeping with Stallman at MIT.\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "ESR's favorite programming language:\n",
      "\n",
      "Objectivist C.\n",
      "\n",
      "\n",
      " href=\"http://web.archive.org/web/20140701124736/http://americanextremists.thecomicseries.com/\n",
      "\">American\n",
      "Extremists\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      " (June 2014)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Made for You (December 2012)\n",
      "(local\n",
      "copyEsperanto\n",
      "translation\n",
      "\n",
      "\n",
      "A science fiction story: Jinnetic\n",
      "Engineeringin\n",
      "Portuguese,\n",
      ",\n",
      ",\n",
      ",\n",
      ",\n",
      ", and\n",
      ").\n",
      "\n",
      "\n",
      "The Right to\n",
      "Read\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "My book of essays about the philosophy of Software Freedom,\n",
      "is available from the\n",
      "\n",
      "GNU Press.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Avec des\n",
      "chapeaux French song parody.\n",
      "\n",
      "\n",
      "\n",
      "My radio program of Music from\n",
      "Georgia, originally broadcast on WUOG in Athens, Georgia on\n",
      "Oct 13, 2014.\n",
      "\n",
      "\n",
      "\n",
      "Resolving the trolley\n",
      "problem\n",
      "\n",
      "\n",
      "Quantum Theory and\n",
      "Abortion Rights\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "proposal for gender neutrality in Spanish, suitable for both\n",
      "speech and writing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ": In June 2000, while\n",
      "visiting Korea, I did a fun hack that clearly illustrates the original\n",
      "and true meaning of the word \"hacker\".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predicting the attack on <a id=\"pearlharbor\"\n",
      "href=\"pearlharbor.html\">Pearl Harbor\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I would like to thank:\n",
      "\n",
      "\n",
      "Graziano Sorbaioli for improving the layout of the main\n",
      "page.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Please send comments on these web pages to .\n",
      "\n",
      "\n",
      "Copyright &copy; 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
      "2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,\n",
      "2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n",
      "Richard Stallman\n",
      "\n",
      "Verbatim copying and redistribution of this entire page are\n",
      "permitted provided this notice is preserved.\n",
      "\n",
      "Verbatim copying and redistribution of any of the photos in the\n",
      " subdirectory is permitted under the\n",
      "\n",
      "Creative\n",
      "Commons Noderivs license version 3.0 or later.  You can copy and\n",
      "redistribute the photo of me playing music to\n",
      "the butterfly under the\n",
      "\n",
      "Creative Commons Noderivs\n",
      "Nocommercial license version 3.0 or later.  Any other photos of\n",
      "me in this (the toplevel) directory may be copied and redistributed under\n",
      "the\n",
      "\n",
      "Creative Commons Noderivs license version 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This works alright but it doesn't work for multiline tags, I'll have to improve it later\n",
    "url = \"https://www.stallman.org/\"\n",
    "html = request.urlopen(url).read().decode(\"utf8\")\n",
    "lines = html.split(\"\\n\")\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    new = re.sub(r\"<.*>\", \"\", line)\n",
    "    new = re.sub(r\"<!--\", \"\", new)\n",
    "    new = re.sub(r\"-->\", \"\", new)\n",
    "    print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "continuous-consumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-term\n"
     ]
    }
   ],
   "source": [
    "regex = \"-\\n\"\n",
    "\n",
    "s = \"\"\"Long-\n",
    "term\"\"\"\n",
    "\n",
    "print(re.sub(regex, \"-\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sophisticated-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R163\n",
      "R150\n",
      "A261\n",
      "A261\n",
      "T520\n",
      "P123\n",
      "H500\n"
     ]
    }
   ],
   "source": [
    "def soundex(name):\n",
    "    name = name[0] + re.sub(r\"a|e|i|o|u|y|h|w\", \"\", name[1:])\n",
    "    name = re.sub(r\"b|f|p|v\", \"1\", name)\n",
    "    name = re.sub(r\"c|g|j|k|q|s|x|z\", \"2\", name)\n",
    "    name = re.sub(r\"d|t\", \"3\", name)\n",
    "    name = re.sub(r\"l\", \"4\", name)\n",
    "    name = re.sub(r\"m|n\", \"5\", name)\n",
    "    name = re.sub(r\"r\", \"6\", name)\n",
    "    newname = \"\"\n",
    "    for i in range(len(name)):\n",
    "        if i < len(name) - 1 and name[i] == name[i+1]:\n",
    "            continue\n",
    "        newname += name[i]\n",
    "    while len(newname) < 4:\n",
    "        newname += \"0\"\n",
    "    if len(newname) > 4:\n",
    "        newname = newname[:4]\n",
    "    return newname\n",
    "\n",
    "print(soundex(\"Robert\"))\n",
    "print(soundex(\"Rubin\"))\n",
    "print(soundex(\"Ashcraft\"))\n",
    "print(soundex(\"Ashcroft\"))\n",
    "print(soundex(\"Tymczak\"))\n",
    "print(soundex(\"Pfister\"))\n",
    "print(soundex(\"Honeyman\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "green-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rural: 68.56955394566279\n",
      "Science: 68.87102766508451\n"
     ]
    }
   ],
   "source": [
    "# The scores below are way too high. Something went wrong in the training. I may not have enough text to accurately tokenize the sentences. Making a note to come back and improve this later.\n",
    "from nltk.corpus import abc, brown\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "def ARI(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    sents = p.tokenize(text)\n",
    "    avg_letters = sum([len(w) for w in words]) / len(words)\n",
    "    avg_words = sum([len(s) for s in sents]) / len(sents)\n",
    "    return (4.71 * avg_letters) + (0.5 * avg_words) - 21.43\n",
    "\n",
    "\n",
    "training_text = brown.raw(categories=\"news\")\n",
    "p = PunktSentenceTokenizer(training_text)\n",
    "\n",
    "rural = abc.raw(fileids=\"rural.txt\")\n",
    "science = abc.raw(fileids=\"science.txt\")\n",
    "\n",
    "print(f\"Rural: {ARI(rural)}\")\n",
    "print(f\"Science: {ARI(science)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "conditional-foundation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['attribution', 'confabulation', 'elocution', 'sequoia', 'tenacious', 'unidirectional']\n",
    "sorted([\"\".join([char for char in word if char in \"aeiou\"]) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-happiness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
